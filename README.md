# RealVsAiImageDetector


**RealVsAiImageDetector** — это веб-приложение на Python, предназначенное для автоматического обнаружения изображений, сгенерированных искусственным интеллектом. Система анализирует входные изображения с помощью собственной нейросетевой модели (на архитектуре U-Net или Vision Transformer) и классифицирует их как «Реальное» или «AI-сгенерированное».

Проект включает в себя полный цикл разработки: от подготовки данных и обучения модели до развертывания веб-интерфейса для пользовательского взаимодействия.

## Содержание

1. [О проекте](#о-проекте)
2. [Архитектура модели](#архитектура-модели)
3. [Технологический стек](#технологический-стек)
4. [Структура репозитория](#структура-репозитория)
5. [Установка и настройка окружения](#установка-и-настройка-окружения)
6. [Подготовка данных](#подготовка-данных)
7. [Обучение модели](#обучение-модели)
8. [Запуск веб-приложения](#запуск-веб-приложения)
9. [Использование API](#использование-api)
10. [Планы развития](#планы-развития)

---

## О проекте

В связи с быстрым развитием генеративных моделей (Diffusion Models, GANs), возникла необходимость в надежных инструментах верификации контента. Данное решение решает задачу бинарной классификации изображений.

**Основные возможности:**
*   Загрузка изображений через веб-интерфейс.
*   Предобработка изображений (нормализация, ресайз).
*   Инференс на обученной модели.
*   Вывод вероятности принадлежности к классу AI и финального вердикта.
*   Визуализация карт активации (опционально, для демонстрации работы U-Net).

---

## Архитектура модели

Проект поддерживает две основные архитектуры для экспериментов и сравнения эффективности:

### 1. U-Net (Адаптированная для классификации)
Изначально созданная для сегментации, архитектура U-Net используется здесь как мощный экстрактор признаков.
*   **Encoder:** Извлекает иерархические признаки из изображения.
*   **Decoder (опционально):** Может использоваться для визуализации областей, наиболее повлиявших на решение (heatmaps).
*   **Classifier Head:** Глобальный пулинг и полносвязные слои для бинарного вывода.
*   *Преимущество:* Эффективная работа с локальными артефактами генерации.

### 2. Vision Transformer (ViT)
Модель на основе механизма внимания (Self-Attention).
*   Разбиение изображения на патчи.
*   Анализ глобальных зависимостей между частями изображения.
*   *Преимущество:* Лучшее выявление структурных несоответствий, характерных для диффузных моделей.



---

## Технологический стек

*   **Язык программирования:** 
*   **Deep Learning фреймворк:** 
*   **Веб-фреймворк:** 
*   **Обработка изображений:** 
*   **Управление зависимостями:**
*   **Визуализация:** 

---

## Структура репозитория

---

## Установка и настройка окружения

Рекомендуется использовать виртуальное окружение (venv или conda).

### 1. Клонирование репозитория


### 2. Создание окружения 


### 3. Установка зависимостей

---

## Подготовка данных

Для обучения модели необходима структура папок с двумя классами:
1.   — Реальные фотографии.
2.   — Изображения, сгенерированные ИИ (Midjourney, Stable Diffusion, DALL-E).


---

## Обучение модели

Запуск процесса обучения осуществляется через скрипт  Параметры задаются в 

**Пример конфигурации :**

**Команда запуска:**

---

## Запуск веб-приложения

После обучения модели можно запустить веб-интерфейс.

**Функционал интерфейса:**
1.  Форма загрузки файла (drag-and-drop).
2.  Отображение загруженного изображения.
3.  Кнопка «Анализировать».
4.  Блок результатов:
    *   Вероятность (в %).
    *   Статус: **REAL** (Зеленый) / **AI GENERATED** (Красный).
    *   График распределения вероятностей.

---

## Авторы

1. Щербатов Павел Романович
2. Шевченко Вероника Александровна
3. Занина Ника Максимовна

Разработано в рамках учебного проекта
